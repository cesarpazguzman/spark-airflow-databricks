version: '2'

services:
  postgres:
    image: postgres:9.6
    volumes: 
        # Create Test database on Postgresql
        - ./AIRFLOW/Postgres_data/pg-init-scripts:/docker-entrypoint-initdb.d
    environment:
        - POSTGRES_USER=airflow
        - POSTGRES_PASSWORD=airflow
        - POSTGRES_DB=airflow
    ports:
        - "5432:5432"
  airflow-webserver:
    image: airflow-spark-container:latest
    restart: always
    depends_on:
        - postgres
        - statsd-exporter
    environment:
        - LOAD_EX=y
        - EXECUTOR=Local
        - POSTGRES_USER=airflow
        - POSTGRES_PASSWORD=airflow
        - POSTGRES_DB=airflow
        - AIRFLOW__SCHEDULER__STATSD_ON=True
        - AIRFLOW__SCHEDULER__STATSD_HOST=statsd-exporter
        - AIRFLOW__SCHEDULER__STATSD_PORT=8125
        - AIRFLOW__SCHEDULER__STATSD_PREFIX=airflow
    volumes:
        - ./AIRFLOW/dags/dags:/usr/local/airflow/dags #DAG folder
        - ./AIRFLOW/dags/spark/app:/usr/local/spark/app
        - ./AIRFLOW/dags/spark/resources:/usr/local/spark/resources #Spark Scripts (Must be the same path in airflow and Spark Cluster)
    ports:
        - "8282:8282"
    command: webserver
    healthcheck:
        test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
        interval: 30s
        timeout: 30s
        retries: 3
  hdfs:
    image: hdfs-namenode:latest
    container_name: hdfs
    volumes:
      - ./CLUSTER_SPARK_HDFS/HDFS/data:/hadoop/data
    environment:
      - CLUSTER_NAME=test
      - "HADOOP_CONF_DIR=/etc/hadoop"
      - "USER=root"
    ports:
      - "9000:9000"
      - "9870:9870"
      - "2222:22"
      
  spark:
    image: spark-custom:latest
    container_name: spark
    depends_on:
      - hdfs
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - CORE_CONF_fs_defaultFS=hdfs://hdfs:9000
    volumes:
      - ./AIRFLOW/dags/spark/app:/usr/local/spark/app 
      - ./AIRFLOW/dags/spark/resources:/usr/local/spark/resources
      - ./CLUSTER_SPARK_HDFS/SPARK/metrics.properties:/opt/bitnami/spark/conf/metrics.properties
    ports:
      - '8080:8080'
      - "7077:7077"
  spark-worker-1:
    image: spark-custom:latest
    container_name: spark-worker1
    depends_on:
      - spark
    ports:
      - "8081:8081"
    environment:
      - SPARK_MASTER=spark://spark:7077
      - CORE_CONF_fs_defaultFS=hdfs://hdfs:9000
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=3G
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./AIRFLOW/dags/spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ./AIRFLOW/dags/spark/resources:/usr/local/spark/resources
  spark-worker-2:
    image: spark-custom:latest
    container_name: spark-worker2
    depends_on:
      - spark
    ports:
      - "8082:8081"
    environment:
      - SPARK_MASTER=spark://spark:7077
      - CORE_CONF_fs_defaultFS=hdfs://hdfs:9000
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=3G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./AIRFLOW/dags/spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ./AIRFLOW/dags/spark/resources:/usr/local/spark/resources
  statsd-exporter:
    image: prom/statsd-exporter:latest
    container_name: airflow-statsd-exporter
    command: "--statsd.listen-udp=:8125 --web.listen-address=:9102"
    ports:
      - 9123:9102
      - 8125:8125/udp
  prometheus:
    image: prom/prometheus:latest
    container_name: airflow-prometheus
    user: "0"
    ports:
      - 9090:9090
    volumes:
      - ./PROMETHEUS/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./PROMETHEUS/volume:/prometheus
  grafana:
    image: grafana/grafana:latest
    container_name: airflow-grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: password
      GF_PATHS_PROVISIONING: /grafana/provisioning
    ports:
      - 3000:3000
    volumes:
      - ./GRAFANA/volume/data:/grafana
      - ./GRAFANA/volume/datasources:/grafana/datasources
      - ./GRAFANA/volume/dashboards:/grafana/dashboards
      - ./GRAFANA/volume/provisioning:/grafana/provisioning
  mlflow_server:
    image: mlflow_tracking_server:latest
    container_name: mlflow_server
    ports:
      - 5000:5000
    volumes:
      - ./MLFLOW_TRACKING_SERVER/mlruns:/mlflow/
